{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6dfb54e-1ae7-493f-9df8-7fed86d9313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on page 1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     date_list\u001b[38;5;241m.\u001b[39mappend(date[\u001b[38;5;241m23\u001b[39m:])\n\u001b[0;32m---> 40\u001b[0m price \u001b[38;5;241m=\u001b[39m \u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcss-1texeil\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m     41\u001b[0m price_list\u001b[38;5;241m.\u001b[39mappend(price[\u001b[38;5;241m8\u001b[39m:])\n\u001b[1;32m     42\u001b[0m address \u001b[38;5;241m=\u001b[39m parent\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh1\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcss-164r41r\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "date_list = []\n",
    "price_list = []\n",
    "address_list = []\n",
    "bedroom_list = []\n",
    "bathroom_list = []\n",
    "parking_list = []\n",
    "area_list = []\n",
    "med_age_list = []\n",
    "pop_list = []\n",
    "avg_age_list = []\n",
    "\n",
    "df1 = pd.read_csv('./page_in_pages.csv')\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:99.0) Gecko/20100101 Firefox/99.0\"}\n",
    "\n",
    "for page in range(1,51):\n",
    "    url = f'https://www.domain.com.au/sold-listings/burnie-tas-7320/?excludepricewithheld=1&landsize=50-any&landsizeunit=m2&ssubs=0&page={page}'\n",
    "    time.sleep(2)\n",
    "    with requests.get(url, headers=headers, stream=True) as response:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        all_divs = soup.find('ul', {'data-testid': 'results', 'class': 'css-8tedj6'})\n",
    "        print(f\"on page {page}\")\n",
    "        for div in all_divs:\n",
    "            ref_link = div.find_next('a', href=True).get('href')\n",
    "            with requests.get(ref_link, headers=headers, stream=True) as response2:\n",
    "                soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "                parent = soup2.find('div', {'class': 'css-fpm9y'})\n",
    "                date = parent.find('span').find_next_sibling('span', {'class': 'css-h9g9i3'}).text\n",
    "                if 'auction' in date:\n",
    "                    date_list.append(date[16:])\n",
    "                else:\n",
    "                    date_list.append(date[23:])\n",
    "                price = parent.find('div', {'class': 'css-1texeil'}).text\n",
    "                price_list.append(price[8:])\n",
    "                address = parent.find('h1', {'class': 'css-164r41r'})\n",
    "                address_list.append(address.text)\n",
    "                dimension_parent = parent.find('div', {'class': 'css-1dtnjt5'})\n",
    "                rooms = dimension_parent.find_all('span', {'class': 'css-lvv8is'})\n",
    "                try:\n",
    "                    bedroom_list.append(rooms[0].text)\n",
    "                except IndexError:\n",
    "                    bedroom_list.append('')\n",
    "                try:\n",
    "                    bathroom_list.append(rooms[1].text)\n",
    "                except IndexError:\n",
    "                    bathroom_list.append('')\n",
    "                try:\n",
    "                    parking_list.append(rooms[2].text)\n",
    "                except IndexError:\n",
    "                    parking_list.append('')\n",
    "                try:\n",
    "                    area_list.append(rooms[3].text)\n",
    "                except IndexError:\n",
    "                    area_list.append('')\n",
    "                try:\n",
    "                    population = soup2.find_all('div', {'class': 'css-8kzdzc'})\n",
    "                    med_age_list.append(population[0].text)\n",
    "                except IndexError:\n",
    "                    med_age_list.append('')\n",
    "                try:\n",
    "                    population = soup2.find_all('div', {'class': 'css-8kzdzc'})\n",
    "                    pop_list.append(population[4].text)\n",
    "                except IndexError:\n",
    "                    pop_list.append('')\n",
    "                try:\n",
    "                    population = soup2.find_all('div', {'class': 'css-8kzdzc'})\n",
    "                    avg_age_list.append(population[5].text)\n",
    "                except IndexError:\n",
    "                    avg_age_list.append('')\n",
    "                    print('-' * 80)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'date': date_list,\n",
    "                   'price': price_list,\n",
    "                   'address': address_list,\n",
    "                   'bedrooms': bedroom_list,\n",
    "                   'bathrooms': bathroom_list,\n",
    "                   'parking': parking_list,\n",
    "                   'area': area_list,\n",
    "                   'median_price': med_age_list,\n",
    "                   'population': pop_list,\n",
    "                   'average_age': avg_age_list})\n",
    "\n",
    "frames = [df1, df]\n",
    "df1 = pd.concat(frames, ignore_index=True)\n",
    "df1.to_csv('page_in_pages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454da4a-8185-4337-93b9-fe4eb465b736",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
